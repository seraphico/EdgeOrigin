# æ–‡ä»¶ç¼“å­˜ç³»ç»Ÿ

åŸºäº BadgerDB å®ç°çš„é«˜æ€§èƒ½æ–‡ä»¶ç¼“å­˜ç³»ç»Ÿï¼Œæ”¯æŒæ–‡ä»¶å­˜å‚¨ã€æ£€ç´¢ã€è¿‡æœŸç®¡ç†å’Œç»Ÿè®¡ä¿¡æ¯ã€‚

## ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½**: åŸºäº BadgerDB çš„ LSM-Tree å­˜å‚¨å¼•æ“
- ğŸ“ **æ–‡ä»¶ç®¡ç†**: æ”¯æŒä»»æ„ç±»å‹æ–‡ä»¶çš„å­˜å‚¨å’Œæ£€ç´¢
- â° **è‡ªåŠ¨è¿‡æœŸ**: æ”¯æŒ TTL å’Œè‡ªåŠ¨æ¸…ç†æœºåˆ¶
- ğŸ“Š **ç»Ÿè®¡ä¿¡æ¯**: æä¾›è¯¦ç»†çš„ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§
- ğŸ”§ **å¯é…ç½®**: çµæ´»çš„é…ç½®é€‰é¡¹
- ğŸ›¡ï¸ **ç±»å‹å®‰å…¨**: å®Œæ•´çš„ Go ç±»å‹ç³»ç»Ÿæ”¯æŒ

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```go
package main

import (
    "context"
    "fmt"
    "strings"
    "time"
    
    "github.com/seraphico/EdgeOrigin/pkg/filecache"
)

func main() {
    // åˆ›å»ºé…ç½®
    config := &filecache.Config{
        DataDir:         "./cache",
        MaxCacheSize:    1024 * 1024 * 1024, // 1GB
        DefaultTTL:      24 * time.Hour,
        CleanupInterval: time.Hour,
        Compression:     true,
    }

    // åˆ›å»ºç¼“å­˜å®ä¾‹
    cache, err := filecache.NewBadgerCache(config)
    if err != nil {
        panic(err)
    }
    defer cache.Close()

    ctx := context.Background()

    // å­˜å‚¨æ–‡ä»¶
    key := "my-file.txt"
    data := strings.NewReader("Hello, World!")
    err = cache.Set(ctx, key, data, "text/plain", time.Hour)
    if err != nil {
        panic(err)
    }

    // è·å–æ–‡ä»¶
    reader, fileInfo, err := cache.Get(ctx, key)
    if err != nil {
        panic(err)
    }
    defer reader.Close()

    // è¯»å–å†…å®¹
    content, _ := io.ReadAll(reader)
    fmt.Printf("Content: %s\n", string(content))
    fmt.Printf("File info: %+v\n", fileInfo)
}
```

### ä½¿ç”¨é»˜è®¤é…ç½®

```go
// ä½¿ç”¨é»˜è®¤é…ç½®
cache, err := filecache.NewBadgerCache(nil)
if err != nil {
    panic(err)
}
defer cache.Close()
```

### ä»é…ç½®æ–‡ä»¶åŠ è½½

```go
// ä»æ–‡ä»¶åŠ è½½é…ç½®
config, err := filecache.LoadConfigFromFile("cache-config.json")
if err != nil {
    panic(err)
}

cache, err := filecache.NewCacheWithConfig(config)
if err != nil {
    panic(err)
}
defer cache.Close()
```

## API å‚è€ƒ

### Cache æ¥å£

```go
type Cache interface {
    // Set å­˜å‚¨æ–‡ä»¶åˆ°ç¼“å­˜
    Set(ctx context.Context, key string, data io.Reader, mimeType string, ttl time.Duration) error
    
    // Get ä»ç¼“å­˜è·å–æ–‡ä»¶
    Get(ctx context.Context, key string) (io.ReadCloser, *FileInfo, error)
    
    // Exists æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    Exists(ctx context.Context, key string) (bool, error)
    
    // Delete åˆ é™¤æ–‡ä»¶
    Delete(ctx context.Context, key string) error
    
    // List åˆ—å‡ºæ‰€æœ‰ç¼“å­˜æ–‡ä»¶
    List(ctx context.Context) ([]*FileInfo, error)
    
    // GetInfo è·å–æ–‡ä»¶ä¿¡æ¯
    GetInfo(ctx context.Context, key string) (*FileInfo, error)
    
    // Cleanup æ¸…ç†è¿‡æœŸæ–‡ä»¶
    Cleanup(ctx context.Context) error
    
    // Close å…³é—­ç¼“å­˜
    Close() error
    
    // Stats è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    Stats() (*Stats, error)
}
```

### é…ç½®é€‰é¡¹

```go
type Config struct {
    DataDir         string        `json:"data_dir"`          // æ•°æ®ç›®å½•
    MaxCacheSize    int64         `json:"max_cache_size"`    // æœ€å¤§ç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    DefaultTTL      time.Duration `json:"default_ttl"`       // é»˜è®¤TTL
    CleanupInterval time.Duration `json:"cleanup_interval"`  // æ¸…ç†é—´éš”
    Compression     bool          `json:"compression"`       // æ˜¯å¦å‹ç¼©
}
```

### æ–‡ä»¶ä¿¡æ¯

```go
type FileInfo struct {
    Key         string    `json:"key"`          // ç¼“å­˜é”®
    Size        int64     `json:"size"`         // æ–‡ä»¶å¤§å°
    MimeType    string    `json:"mime_type"`    // MIMEç±»å‹
    CreatedAt   time.Time `json:"created_at"`   // åˆ›å»ºæ—¶é—´
    ExpiresAt   time.Time `json:"expires_at"`   // è¿‡æœŸæ—¶é—´
    AccessCount int64     `json:"access_count"` // è®¿é—®æ¬¡æ•°
    LastAccess  time.Time `json:"last_access"`  // æœ€åè®¿é—®æ—¶é—´
}
```

## é«˜çº§ç”¨æ³•

### æ‰¹é‡æ“ä½œ

```go
// æ‰¹é‡å­˜å‚¨æ–‡ä»¶
files := map[string]string{
    "file1.txt": "Content 1",
    "file2.txt": "Content 2",
    "file3.txt": "Content 3",
}

for key, content := range files {
    err := cache.Set(ctx, key, strings.NewReader(content), "text/plain", time.Hour)
    if err != nil {
        log.Printf("Failed to store %s: %v", key, err)
    }
}

// åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
fileList, err := cache.List(ctx)
if err != nil {
    panic(err)
}

for _, file := range fileList {
    fmt.Printf("File: %s, Size: %d, Type: %s\n", 
        file.Key, file.Size, file.MimeType)
}
```

### ç›‘æ§å’Œç»Ÿè®¡

```go
// è·å–ç»Ÿè®¡ä¿¡æ¯
stats, err := cache.Stats()
if err != nil {
    panic(err)
}

fmt.Printf("Total files: %d\n", stats.TotalFiles)
fmt.Printf("Total size: %d bytes\n", stats.TotalSize)
fmt.Printf("Hit rate: %.2f%%\n", stats.HitRate*100)
fmt.Printf("Miss rate: %.2f%%\n", stats.MissRate*100)
fmt.Printf("Expired files: %d\n", stats.ExpiredFiles)
```

### è‡ªå®šä¹‰è¿‡æœŸç­–ç•¥

```go
// è®¾ç½®ä¸åŒçš„TTL
cache.Set(ctx, "short-lived", data1, "text/plain", time.Minute)
cache.Set(ctx, "long-lived", data2, "text/plain", time.Hour*24)
cache.Set(ctx, "permanent", data3, "text/plain", time.Hour*24*365)

// æ‰‹åŠ¨æ¸…ç†è¿‡æœŸæ–‡ä»¶
err := cache.Cleanup(ctx)
if err != nil {
    log.Printf("Cleanup failed: %v", err)
}
```

## æ€§èƒ½ä¼˜åŒ–

1. **å¯ç”¨å‹ç¼©**: è®¾ç½® `Compression: true` å¯ä»¥å‡å°‘å­˜å‚¨ç©ºé—´
2. **åˆç†è®¾ç½®ç¼“å­˜å¤§å°**: æ ¹æ®å¯ç”¨å†…å­˜è®¾ç½® `MaxCacheSize`
3. **å®šæœŸæ¸…ç†**: è®¾ç½®åˆé€‚çš„ `CleanupInterval` é¿å…è¿‡æœŸæ–‡ä»¶ç§¯ç´¯
4. **æ‰¹é‡æ“ä½œ**: å°½é‡æ‰¹é‡å¤„ç†æ–‡ä»¶ä»¥æé«˜æ•ˆç‡

## æ³¨æ„äº‹é¡¹

1. **èµ„æºç®¡ç†**: ä½¿ç”¨å®Œæ¯•ååŠ¡å¿…è°ƒç”¨ `Close()` æ–¹æ³•
2. **å¹¶å‘å®‰å…¨**: ç¼“å­˜å®ä¾‹æ˜¯å¹¶å‘å®‰å…¨çš„ï¼Œå¯ä»¥åœ¨å¤šä¸ª goroutine ä¸­ä½¿ç”¨
3. **é”™è¯¯å¤„ç†**: æ‰€æœ‰æ“ä½œéƒ½å¯èƒ½è¿”å›é”™è¯¯ï¼Œè¯·å¦¥å–„å¤„ç†
4. **å†…å­˜ä½¿ç”¨**: å¤§æ–‡ä»¶ä¼šå ç”¨è¾ƒå¤šå†…å­˜ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´é…ç½®

## æµ‹è¯•

è¿è¡Œæµ‹è¯•ï¼š

```bash
go test ./pkg/filecache/...
```

è¿è¡Œç¤ºä¾‹ï¼š

```bash
go run ./pkg/filecache/example_test.go
```
